"""
LoanGuard - ML Model Training with Bank Recommendation Engine (Stable Version)
✅ Works with your dataset columns:
['applicantName', 'age', 'employment', 'yearsEmployed', 'annualIncome',
 'creditScore', 'pastDefaults', 'loanAmount', 'loanTerm', 'interestRate', 'loanType', 'verdict']
✅ Handles missing 'existingDebt' safely
✅ Handles single-class datasets (no crash)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle
import warnings
warnings.filterwarnings('ignore')


# ==================== STEP 1: LOAD & PREPROCESS DATA ====================

def load_and_preprocess_data(csv_file):
    """Load and preprocess Indian loan data."""
    print("📊 Loading Indian customer data...")
    df = pd.read_csv(csv_file)
    print(f"✅ Loaded dataset with {df.shape[0]} records and {df.shape[1]} columns.\n")

    # Rename columns to standard names
    df = df.rename(columns={
        'yearsEmployed': 'emp_length',
        'annualIncome': 'annual_inc',
        'creditScore': 'fico_range_low',
        'loanAmount': 'loan_amnt',
        'loanTerm': 'term',
        'interestRate': 'int_rate',
        'verdict': 'loan_status'
    })

    # Check required columns
    required_cols = ['age', 'emp_length', 'annual_inc', 'fico_range_low', 'loan_amnt', 'term', 'int_rate', 'loan_status']
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns: {missing}")

    # Handle missing or missing-debt column
    if 'existingDebt' in df.columns:
        df['dti'] = (df['existingDebt'] / df['annual_inc']).fillna(0)
    else:
        print("⚠️ 'existingDebt' column not found. Using default DTI = 0.3.")
        df['dti'] = 0.3

    df.fillna(df.median(numeric_only=True), inplace=True)

    # Binary target
    df['is_default'] = df['loan_status'].apply(
        lambda x: 1 if str(x).lower() in ['rejected', 'default', 'denied', 'no'] else 0
    )

    print("✅ Data preprocessed successfully!\n")
    return df


# ==================== STEP 2: LOAD BANK DATA ====================

def load_banks_data(banks_csv_file):
    """Load Indian banks' interest rates data."""
    print("🏦 Loading Indian banks data...")
    banks_df = pd.read_csv(banks_csv_file)

    # Remove category headers
    category_keywords = ['Public Sector', 'Small Finance', 'Interest Rates']
    mask = ~banks_df['Bank Name'].str.contains('|'.join(category_keywords), case=False, na=False)
    banks_df = banks_df[mask].reset_index(drop=True)

    # Convert rate columns to numeric
    int_rate_cols = ['Highest Slab', '1 year tenure', '3 year tenure', '5 year tenure', 'Senior Citizens']
    for col in int_rate_cols:
        banks_df[col] = pd.to_numeric(banks_df[col], errors='coerce')

    print(f"✅ Loaded {len(banks_df)} banks successfully.\n")
    return banks_df


# ==================== STEP 3: FEATURE ENGINEERING ====================

def engineer_features(df):
    """Create new features for model training."""
    print("🔧 Engineering features...")

    df['monthly_income'] = df['annual_inc'] / 12
    df['loan_to_income'] = df['loan_amnt'] / df['annual_inc']
    df['credit_score'] = df['fico_range_low']
    df['emp_length_clean'] = pd.to_numeric(df['emp_length'], errors='coerce').fillna(0).astype(int)
    df['income_stability'] = np.where(df['emp_length_clean'] >= 5, 0.8,
                                      np.where(df['emp_length_clean'] >= 2, 0.6, 0.4))

    print("✅ Feature engineering completed!\n")
    return df


# ==================== STEP 4: MODEL DATA PREPARATION ====================

def prepare_model_data(df):
    """Prepare training and test data."""
    print("⚙️ Preparing data for training...")

    feature_columns = [
        'age', 'emp_length_clean', 'annual_inc', 'dti',
        'credit_score', 'loan_amnt', 'int_rate', 'loan_to_income', 'income_stability'
    ]
    X = df[feature_columns]
    y = df['is_default']

    for col in X.select_dtypes(include=['object']).columns:
        X[col] = LabelEncoder().fit_transform(X[col])

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    print(f"✅ Train size: {X_train.shape}, Test size: {X_test.shape}\n")
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_columns


# ==================== STEP 5: TRAIN MODEL ====================

def train_model(X_train, X_test, y_train, y_test):
    """Train Random Forest model."""
    print("🤖 Training Random Forest model...")
    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    print(f"📊 Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"📊 Precision: {precision_score(y_test, y_pred, zero_division=0):.4f}")
    print(f"📊 Recall: {recall_score(y_test, y_pred, zero_division=0):.4f}")
    print(f"📊 F1 Score: {f1_score(y_test, y_pred, zero_division=0):.4f}\n")

    print("✅ Model training complete!\n")
    return model


# ==================== STEP 6: BANK RECOMMENDATION ENGINE ====================

def get_bank_recommendations(customer_profile, model, scaler, feature_columns, banks_df, loan_tenure='1 year tenure'):
    """Recommend banks safely even for single-class model."""
    print("\n🏦 Generating Bank Recommendations...\n")

    customer_data = pd.DataFrame([customer_profile])
    customer_data_scaled = scaler.transform(customer_data[feature_columns])

    # Handle single-class model safely
    try:
        probs = model.predict_proba(customer_data_scaled)[0]
        if probs.shape[0] == 1:
            print("⚠️ Model only trained on one class. Assigning default risk = 0.5.\n")
            default_risk = 0.5
        else:
            default_risk = probs[1]
    except Exception as e:
        print(f"⚠️ Could not compute probability ({e}). Assigning default risk = 0.5.\n")
        default_risk = 0.5

    print(f"📉 Default Risk: {default_risk:.2%}\n")

    eligible_banks = banks_df[banks_df[loan_tenure].notna()].copy()
    if eligible_banks.empty:
        print("❌ No bank data found for this tenure.")
        return []

    min_rate = eligible_banks[loan_tenure].min()
    max_rate = eligible_banks[loan_tenure].max()

    eligible_banks['int_rate_score'] = 1 - ((eligible_banks[loan_tenure] - min_rate) / (max_rate - min_rate)).clip(0, 1)
    risk_factor = 0.85 if default_risk < 0.2 else (0.65 if default_risk < 0.4 else 0.45)
    eligible_banks['risk_score'] = risk_factor
    eligible_banks['lti_score'] = max(0, 1 - customer_profile['loan_to_income'])

    eligible_banks['suitability_score'] = (
        eligible_banks['int_rate_score'] * 0.5 +
        eligible_banks['risk_score'] * 0.3 +
        eligible_banks['lti_score'] * 0.2
    )

    recommendations = eligible_banks.sort_values('suitability_score', ascending=False).head(10)

    print("✅ Top 5 Recommended Banks:\n")
    for idx, row in recommendations.head(5).iterrows():
        print(f"{idx + 1}. {row['Bank Name']} - {row[loan_tenure]:.2f}% "
              f"(Suitability: {row['suitability_score']:.2%})")

    return recommendations.to_dict('records')


# ==================== STEP 7: SAVE MODEL ====================

def save_model(model, scaler, feature_columns):
    """Save trained model and preprocessing artifacts."""
    print("💾 Saving model artifacts...")
    with open('loan_model.pkl', 'wb') as f:
        pickle.dump(model, f)
    with open('scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    with open('feature_columns.pkl', 'wb') as f:
        pickle.dump(feature_columns, f)
    print("✅ Model saved!\n")


# ==================== SAMPLE PREDICTION ====================

def predict_for_customer(age, emp_length, annual_inc, dti, credit_score, loan_amnt, int_rate,
                         model, scaler, feature_columns, banks_df, loan_tenure='1 year tenure'):
    """Make prediction for sample user."""
    profile = {
        'age': age,
        'emp_length_clean': emp_length,
        'annual_inc': annual_inc,
        'dti': dti,
        'credit_score': credit_score,
        'loan_amnt': loan_amnt,
        'int_rate': int_rate,
        'loan_to_income': loan_amnt / annual_inc,
        'income_stability': 0.8 if emp_length >= 5 else (0.6 if emp_length >= 2 else 0.4)
    }
    return get_bank_recommendations(profile, model, scaler, feature_columns, banks_df, loan_tenure)


# ==================== MAIN EXECUTION ====================

if __name__ == "__main__":
    print("=" * 70)
    print("🚀 LoanGuard - Indian Bank Recommendation System (Stable)")
    print("=" * 70 + "\n")

    try:
        df = load_and_preprocess_data('loans_dataset_500_records_INR.csv')
        banks_df = load_banks_data('Banks-Interest-Rates_india.csv')

        df = engineer_features(df)
        X_train, X_test, y_train, y_test, scaler, feature_columns = prepare_model_data(df)
        model = train_model(X_train, X_test, y_train, y_test)
        save_model(model, scaler, feature_columns)

        predict_for_customer(
            age=35,
            emp_length=7,
            annual_inc=1200000,
            dti=0.35,
            credit_score=750,
            loan_amnt=1000000,
            int_rate=8.5,
            model=model,
            scaler=scaler,
            feature_columns=feature_columns,
            banks_df=banks_df,
            loan_tenure='1 year tenure'
        )

    except Exception as e:
        print(f"❌ Error: {str(e)}")
        import traceback
        traceback.print_exc()
